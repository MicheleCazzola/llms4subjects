{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43b8e39",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonPlusSign/llms4subjects/blob/main/embedding_similarity_tagging.ipynb)\n",
    "\n",
    "# Embedding Similarity Tagging\n",
    "\n",
    "The goal of this notebook is to run the `embedding_similarity_tagging.py` script with different parameters (e.g. different embedding models).\n",
    "\n",
    "The script uses a SentenceTransformer model to encode document texts and tag embeddings,\n",
    "and then computes the similarity between them to tag the documents with the most similar GND tags.\n",
    "\n",
    "The quality of the tagging results is evaluated using the `shared-task-eval-script/llms4subjects-evaluation.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f2bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llms4subjects'...\n",
      "remote: Enumerating objects: 818255, done.\u001b[K\n",
      "remote: Counting objects: 100% (23179/23179), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5048/5048), done.\u001b[K\n",
      "remote: Total 818255 (delta 22310), reused 18270 (delta 18125), pack-reused 795076 (from 2)\u001b[K\n",
      "Receiving objects: 100% (818255/818255), 1.04 GiB | 17.34 MiB/s, done.\n",
      "Resolving deltas: 100% (763823/763823), done.\n",
      "Updating files: 100% (889015/889015), done.\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu124)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.19.6)\n",
      "Collecting datasets (from -r requirements.txt (line 5))\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fvcore (from -r requirements.txt (line 8))\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (3.10.0)\n",
      "Requirement already satisfied: sentence-transformers[train] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.48.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 3))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (4.25.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements.txt (line 4)) (75.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 5))\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]->-r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]->-r requirements.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]->-r requirements.txt (line 6)) (11.1.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers[train]->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 7)) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->-r requirements.txt (line 7)) (0.5.2)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/yacs/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting yacs>=0.1.6 (from fvcore->-r requirements.txt (line 8))\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore->-r requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore->-r requirements.txt (line 8)) (0.9.0)\n",
      "Collecting iopath>=0.1.7 (from fvcore->-r requirements.txt (line 8))\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 9)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4)) (4.0.12)\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore->-r requirements.txt (line 8))\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->-r requirements.txt (line 4)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers[train]->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers[train]->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 4)) (5.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: fvcore, iopath\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=86b861023fec5b16fedc0bab329f6d3390b77486812a2112c37caa54e0e2d8d2\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=d795eff9b3afaad9ed31c91b8dc8d07babae7310e30527ed07c8404983e541dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
      "Successfully built fvcore iopath\n",
      "Installing collected packages: yacs, xxhash, portalocker, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, iopath, nvidia-cusolver-cu12, fvcore, datasets\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed datasets-3.3.2 dill-0.3.8 fvcore-0.1.5.post20221221 iopath-0.1.10 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 portalocker-3.1.1 xxhash-3.5.0 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "# If you run this notebook in Google Colab, run this\n",
    "\n",
    "# Clone repository and move its content in the current directory\n",
    "!git clone https://github.com/RonPlusSign/llms4subjects.git\n",
    "!mv llms4subjects/* .\n",
    "!rm -r llms4subjects\n",
    "\n",
    "# Install required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e291c6cdff596",
   "metadata": {},
   "source": [
    "#### Tagging with Different Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddebb865d09575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T16:43:19.441800Z",
     "start_time": "2025-02-18T16:43:19.437462Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"distiluse-base-multilingual-cased-v1\",\n",
    "    \"T-Systems-onsite/cross-en-de-roberta-sentence-transformer\",  # this gives warning \"No sentence-transformers model found with name ...\", but it's ok\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95abf7cda27ebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:04:41.818900Z",
     "start_time": "2025-02-18T16:43:29.530764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Running tagging with model: sentence-transformers/all-MiniLM-L6-v2 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\andre\\Desktop\\llms4subjects\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:17<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:31<00:00, 46.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: distiluse-base-multilingual-cased-v1 ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [04:22<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:41<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: T-Systems-onsite/cross-en-de-roberta-sentence-transformer ------\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name T-Systems-onsite/cross-en-de-roberta-sentence-transformer. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [09:01<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [07:12<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: intfloat/multilingual-e5-large ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [25:40<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [20:48<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    model_name_folder = model_name.split(\"/\")[-1]\n",
    "    tag_embeddings_file = f\"results/{model_name_folder}/tag_embeddings.json\"  # Where to save the tag embeddings\n",
    "    results_dir = f\"results/{model_name_folder}\"  # Where to save the tagging results\n",
    "    docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"  # Documents to tag\n",
    "    tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "\n",
    "    print(f\"\\n------Running tagging with model: {model_name} ------\")\n",
    "    %run embedding_similarity_tagging.py \\\n",
    "            --model_name { model_name } \\\n",
    "            --tags_file { tag_file } \\\n",
    "            --tag_embeddings_file { tag_embeddings_file } \\\n",
    "            --results_dir { results_dir } \\\n",
    "            --docs_path { docs_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a565e13ca69209",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0e5c01e5f754d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T18:08:57.481245Z",
     "start_time": "2025-02-18T18:04:41.954643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Evaluating tagging results for model: sentence-transformers/all-MiniLM-L6-v2 ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/all-MiniLM-L6-v2/all-MiniLM-L6-v2_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating tagging results for model: distiluse-base-multilingual-cased-v1 ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/distiluse-base-multilingual-cased-v1/distiluse-base-multilingual-cased-v1_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating tagging results for model: T-Systems-onsite/cross-en-de-roberta-sentence-transformer ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/cross-en-de-roberta-sentence-transformer/cross-en-de-roberta-sentence-transformer_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating tagging results for model: intfloat/multilingual-e5-large ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/multilingual-e5-large/multilingual-e5-large_evaluation_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tagging results using the evaluation script.\n",
    "for model_name in models:\n",
    "    print(f\"\\n------Evaluating tagging results for model: {model_name} ------\")\n",
    "\n",
    "    model_name_folder = model_name.split(\"/\")[-1]\n",
    "    true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "    pred_labels_dir = f\"results/{model_name_folder}\"\n",
    "    results_dir = f\"results/{model_name_folder}\"\n",
    "\n",
    "    %run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "            --team_name { model_name_folder } \\\n",
    "            --true_labels_dir { true_labels_dir } \\\n",
    "            --pred_labels_dir { pred_labels_dir } \\\n",
    "            --results_dir { results_dir }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b55bd4ce42a57",
   "metadata": {},
   "source": [
    "## SentenceTransformer fine-tuning\n",
    "\n",
    "The `finetune_sentence_transformer.py` script fine-tunes a SentenceTransformer model on training data for subject tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d183ab03cb8e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T23:22:38.445559Z",
     "start_time": "2025-02-19T23:22:38.437483Z"
    }
   },
   "outputs": [],
   "source": [
    "# List of models to fine-tune\n",
    "models = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    # \"distiluse-base-multilingual-cased-v1\",\n",
    "    # \"T-Systems-onsite/cross-en-de-roberta-sentence-transformer\", # this gives warning \"No sentence-transformers model found with name ...\", but it's ok\n",
    "    # \"intfloat/multilingual-e5-large\",\n",
    "]\n",
    "\n",
    "# Extract the base model names (e.g., from \"sentence-transformers/all-MiniLM-L6-v2\" take \"all-MiniLM-L6-v2\")\n",
    "model_names = [model_name.split(\"/\")[-1] for model_name in models]\n",
    "\n",
    "# Define the list of losses to test\n",
    "losses = [\"coSENT\", \"AnglE\", \"CosineSimilarity\", \"MultipleNegativesRanking\", \"Triplet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080c1a767866eef",
   "metadata": {},
   "source": [
    "#### Execute fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1194441507d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T17:56:23.722967Z",
     "start_time": "2025-02-19T11:47:30.049198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Fine-tuning model: sentence-transformers/all-MiniLM-L6-v2 ------\n",
      "Using loss: coSENT, saving to: models/finetuned/all-MiniLM-L6-v2_coSENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\andre\\Desktop\\llms4subjects\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model...\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Created 14711 evaluation examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: andrea-delli (andrea-delli-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\andre\\Desktop\\llms4subjects\\wandb\\run-20250219_124751-wvjx0rjy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/wvjx0rjy' target=\"_blank\">finetune_all-MiniLM-L6-v2_coSENTLoss</a></strong> to <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/wvjx0rjy' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/wvjx0rjy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10987' max='10987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10987/10987 1:27:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.408500</td>\n",
       "      <td>0.669412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.927000</td>\n",
       "      <td>0.588041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>0.451133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.460791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.260500</td>\n",
       "      <td>0.368131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.298800</td>\n",
       "      <td>0.399303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.173900</td>\n",
       "      <td>0.355184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.002100</td>\n",
       "      <td>0.311243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.057100</td>\n",
       "      <td>0.293465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.021500</td>\n",
       "      <td>0.274140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to models/finetuned/all-MiniLM-L6-v2_coSENT.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▄▄▃▃▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▂▁▁▅█▅▅▆▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▇██▄▁▄▃▃▇█</td></tr><tr><td>eval/steps_per_second</td><td>▇██▄▁▄▃▃▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▂▂▇▂▅▁▃▁█▁</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.27414</td></tr><tr><td>eval/runtime</td><td>173.9312</td></tr><tr><td>eval/samples_per_second</td><td>169.159</td></tr><tr><td>eval/steps_per_second</td><td>21.146</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>10987</td></tr><tr><td>train/grad_norm</td><td>0.00283</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0215</td></tr><tr><td>train_loss</td><td>1.39088</td></tr><tr><td>train_runtime</td><td>5271.7505</td></tr><tr><td>train_samples_per_second</td><td>33.346</td></tr><tr><td>train_steps_per_second</td><td>2.084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune_all-MiniLM-L6-v2_coSENTLoss</strong> at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/wvjx0rjy' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/wvjx0rjy</a><br> View project at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250219_124751-wvjx0rjy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss: AnglE, saving to: models/finetuned/all-MiniLM-L6-v2_AnglE\n",
      "Using device: cuda\n",
      "Loading model...\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Created 14711 evaluation examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\andre\\Desktop\\llms4subjects\\wandb\\run-20250219_141601-rgo6xajy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/rgo6xajy' target=\"_blank\">finetune_all-MiniLM-L6-v2_AnglELoss</a></strong> to <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/rgo6xajy' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/rgo6xajy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10987' max='10987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10987/10987 1:33:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.708900</td>\n",
       "      <td>0.726152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.000800</td>\n",
       "      <td>0.685210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.825400</td>\n",
       "      <td>0.507084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.544500</td>\n",
       "      <td>0.505828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.346300</td>\n",
       "      <td>0.416654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.377200</td>\n",
       "      <td>0.419160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.252200</td>\n",
       "      <td>0.369957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.052100</td>\n",
       "      <td>0.352722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.054700</td>\n",
       "      <td>0.339808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.045600</td>\n",
       "      <td>0.306802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to models/finetuned/all-MiniLM-L6-v2_AnglE.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▄▄▃▃▂▂▂▁</td></tr><tr><td>eval/runtime</td><td>▄█▃▃▃▂▂▁▄▂</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▆▆▆▇▇█▅▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▆▆▆▇▇█▅▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▅▄▃▂▆▁▇▁█▁</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.3068</td></tr><tr><td>eval/runtime</td><td>193.2063</td></tr><tr><td>eval/samples_per_second</td><td>152.283</td></tr><tr><td>eval/steps_per_second</td><td>19.037</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>10987</td></tr><tr><td>train/grad_norm</td><td>0.0228</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0456</td></tr><tr><td>train_loss</td><td>1.47274</td></tr><tr><td>train_runtime</td><td>5594.9124</td></tr><tr><td>train_samples_per_second</td><td>31.42</td></tr><tr><td>train_steps_per_second</td><td>1.964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune_all-MiniLM-L6-v2_AnglELoss</strong> at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/rgo6xajy' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/rgo6xajy</a><br> View project at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250219_141601-rgo6xajy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss: CosineSimilarity, saving to: models/finetuned/all-MiniLM-L6-v2_CosineSimilarity\n",
      "Using device: cuda\n",
      "Loading model...\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Created 14711 evaluation examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\andre\\Desktop\\llms4subjects\\wandb\\run-20250219_154931-0aat84zo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/0aat84zo' target=\"_blank\">finetune_all-MiniLM-L6-v2_CosineSimilarityLoss</a></strong> to <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/0aat84zo' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/0aat84zo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10987' max='10987' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10987/10987 1:35:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.083757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.067603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.064060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.059908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.058677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.056789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.053862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.052989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.050934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.050552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to models/finetuned/all-MiniLM-L6-v2_CosineSimilarity.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁█▇▇▇▇▆▃</td></tr><tr><td>eval/samples_per_second</td><td>███▁▂▂▂▂▃▆</td></tr><tr><td>eval/steps_per_second</td><td>███▁▂▂▂▂▃▆</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇█</td></tr><tr><td>train/grad_norm</td><td>▅▄▄▄█▁▅▂▆▁</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▄▃▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.05055</td></tr><tr><td>eval/runtime</td><td>205.5515</td></tr><tr><td>eval/samples_per_second</td><td>143.137</td></tr><tr><td>eval/steps_per_second</td><td>17.893</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>10987</td></tr><tr><td>train/grad_norm</td><td>0.30053</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0526</td></tr><tr><td>train_loss</td><td>0.06537</td></tr><tr><td>train_runtime</td><td>5714.8332</td></tr><tr><td>train_samples_per_second</td><td>30.761</td></tr><tr><td>train_steps_per_second</td><td>1.923</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune_all-MiniLM-L6-v2_CosineSimilarityLoss</strong> at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/0aat84zo' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/0aat84zo</a><br> View project at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250219_154931-0aat84zo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss: MultipleNegativesRanking, saving to: models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking\n",
      "Using device: cuda\n",
      "Loading model...\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Created 14711 evaluation examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\andre\\Desktop\\llms4subjects\\wandb\\run-20250219_172501-zsfmnwq9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/zsfmnwq9' target=\"_blank\">finetune_all-MiniLM-L6-v2_MultipleNegativesRankingLoss</a></strong> to <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/zsfmnwq9' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/zsfmnwq9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5494' max='5494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5494/5494 40:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>0.407056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.335982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.302286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>0.279303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>0.264122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▃▂▁</td></tr><tr><td>eval/runtime</td><td>▆▁▃█▆</td></tr><tr><td>eval/samples_per_second</td><td>▃█▆▁▃</td></tr><tr><td>eval/steps_per_second</td><td>▃█▆▁▃</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/grad_norm</td><td>▇▆▅█▁</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.26412</td></tr><tr><td>eval/runtime</td><td>108.057</td></tr><tr><td>eval/samples_per_second</td><td>136.141</td></tr><tr><td>eval/steps_per_second</td><td>17.019</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>5494</td></tr><tr><td>train/grad_norm</td><td>8.43434</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4813</td></tr><tr><td>train_loss</td><td>0.60807</td></tr><tr><td>train_runtime</td><td>2420.1779</td></tr><tr><td>train_samples_per_second</td><td>36.318</td></tr><tr><td>train_steps_per_second</td><td>2.27</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune_all-MiniLM-L6-v2_MultipleNegativesRankingLoss</strong> at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/zsfmnwq9' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/zsfmnwq9</a><br> View project at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250219_172501-zsfmnwq9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss: Triplet, saving to: models/finetuned/all-MiniLM-L6-v2_Triplet\n",
      "Using device: cuda\n",
      "Loading model...\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Created 14711 evaluation examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\andre\\Desktop\\llms4subjects\\wandb\\run-20250219_180534-6qanqd1a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/6qanqd1a' target=\"_blank\">finetune_all-MiniLM-L6-v2_TripletLoss</a></strong> to <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/6qanqd1a' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/6qanqd1a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5494' max='5494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5494/5494 50:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.146700</td>\n",
       "      <td>3.918621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.855800</td>\n",
       "      <td>3.748374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.779700</td>\n",
       "      <td>3.729603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.750900</td>\n",
       "      <td>3.691578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.721100</td>\n",
       "      <td>3.691401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to models/finetuned/all-MiniLM-L6-v2_Triplet.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▂▁▁</td></tr><tr><td>eval/runtime</td><td>▁▂▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇██▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇██▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/grad_norm</td><td>▃▁█▁▁</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>3.6914</td></tr><tr><td>eval/runtime</td><td>136.7844</td></tr><tr><td>eval/samples_per_second</td><td>107.549</td></tr><tr><td>eval/steps_per_second</td><td>13.445</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>5494</td></tr><tr><td>train/grad_norm</td><td>0.71183</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.7211</td></tr><tr><td>train_loss</td><td>3.83536</td></tr><tr><td>train_runtime</td><td>3046.686</td></tr><tr><td>train_samples_per_second</td><td>28.85</td></tr><tr><td>train_steps_per_second</td><td>1.803</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">finetune_all-MiniLM-L6-v2_TripletLoss</strong> at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/6qanqd1a' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers/runs/6qanqd1a</a><br> View project at: <a href='https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers' target=\"_blank\">https://wandb.ai/andrea-delli-politecnico-di-torino/sentence-transformers</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250219_180534-6qanqd1a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finetune all SentenceTransformer models on the training data for each loss function\n",
    "for model_name in models:\n",
    "    print(f\"\\n------Fine-tuning model: {model_name} ------\")\n",
    "    model_name_clean = model_name.split(\"/\")[-1]\n",
    "\n",
    "    # Common directories and files\n",
    "    training_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/train\"\n",
    "    eval_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "    gnd_tags_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"\n",
    "\n",
    "    for loss in losses:\n",
    "        # Modify the output path to include the loss function name\n",
    "        output_model_path = f\"models/finetuned/{model_name_clean}_{loss}\"\n",
    "        print(f\"Using loss: {loss}, saving to: {output_model_path}\")\n",
    "\n",
    "        # Run the fine-tuning script with the specified loss\n",
    "        %run finetune_sentence_transformer.py \\\n",
    "                --training_path { training_data_dir } \\\n",
    "                --eval_path { eval_data_dir } \\\n",
    "                --gnd_tags_file { gnd_tags_file } \\\n",
    "                --model_name { model_name } \\\n",
    "                --output_model_path { output_model_path } \\\n",
    "                --batch_size 16 \\\n",
    "                --num_epochs 1 \\\n",
    "                --loss { loss }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7622723d1cf5603",
   "metadata": {},
   "source": [
    "#### Tag using the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2aa87811249f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:04:17.469114Z",
     "start_time": "2025-02-19T18:38:58.923892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_coSENT (loss: coSENT) ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\andre\\Desktop\\llms4subjects\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:16<00:00, 32.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [03:11<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_AnglE (loss: AnglE) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:17<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:54<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_CosineSimilarity (loss: CosineSimilarity) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:16<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:48<00:00, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking (loss: MultipleNegativesRanking) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:15<00:00, 32.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:16<00:00, 50.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_Triplet (loss: Triplet) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:15<00:00, 32.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:17<00:00, 50.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each model and each loss, run tagging\n",
    "for model_name in model_names:\n",
    "    for loss in losses:\n",
    "        # Construct the path where the finetuned model is saved\n",
    "        finetuned_model_path = f\"models/finetuned/{model_name}_{loss}\"\n",
    "        # Use a folder name that includes both the model and loss to save the tagging results\n",
    "        model_name_folder = f\"{model_name}_{loss}\"\n",
    "        tag_embeddings_file = f\"results/finetuned_{model_name_folder}/tag_embeddings.json\"  # Where to save the tag embeddings\n",
    "        results_dir = f\"results/finetuned_{model_name_folder}\"  # Where to save the tagging results\n",
    "        docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"  # Documents to tag\n",
    "        tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "\n",
    "        print(f\"\\n------Running tagging with model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "        %run embedding_similarity_tagging.py \\\n",
    "                --model_name { finetuned_model_path } \\\n",
    "                --tags_file { tag_file } \\\n",
    "                --tag_embeddings_file { tag_embeddings_file } \\\n",
    "                --results_dir { results_dir } \\\n",
    "                --docs_path { docs_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c30c1b5024d589",
   "metadata": {},
   "source": [
    "#### Evaluate the fine-tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag using the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_coSENT (loss: coSENT) ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\andre\\Desktop\\llms4subjects\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:16<00:00, 32.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [03:11<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_AnglE (loss: AnglE) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:17<00:00, 31.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:54<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_CosineSimilarity (loss: CosineSimilarity) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:16<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:48<00:00, 41.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking (loss: MultipleNegativesRanking) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:15<00:00, 32.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:16<00:00, 50.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n",
      "\n",
      "------Running tagging with model: models/finetuned/all-MiniLM-L6-v2_Triplet (loss: Triplet) ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2483/2483 [01:15<00:00, 32.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging documents: 100%|██████████| 6980/6980 [02:17<00:00, 50.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For each model and each loss, run tagging\n",
    "for model_name in model_names:\n",
    "    for loss in losses:\n",
    "        # Construct the path where the finetuned model is saved\n",
    "        finetuned_model_path = f\"models/finetuned/{model_name}_{loss}\"\n",
    "        # Use a folder name that includes both the model and loss to save the tagging results\n",
    "        model_name_folder = f\"{model_name}_{loss}\"\n",
    "        tag_embeddings_file = f\"results/finetuned_{model_name_folder}/tag_embeddings.json\"  # Where to save the tag embeddings\n",
    "        results_dir = f\"results/finetuned_{model_name_folder}\"  # Where to save the tagging results\n",
    "        docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"  # Documents to tag\n",
    "        tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "\n",
    "        print(f\"\\n------Running tagging with model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "        %run embedding_similarity_tagging.py \\\n",
    "                --model_name { finetuned_model_path } \\\n",
    "                --tags_file { tag_file } \\\n",
    "                --tag_embeddings_file { tag_embeddings_file } \\\n",
    "                --results_dir { results_dir } \\\n",
    "                --docs_path { docs_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_coSENT (loss: coSENT) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_coSENT/finetuned_all-MiniLM-L6-v2_coSENT_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_AnglE (loss: AnglE) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_AnglE/finetuned_all-MiniLM-L6-v2_AnglE_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_CosineSimilarity (loss: CosineSimilarity) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_CosineSimilarity/finetuned_all-MiniLM-L6-v2_CosineSimilarity_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking (loss: MultipleNegativesRanking) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_MultipleNegativesRanking/finetuned_all-MiniLM-L6-v2_MultipleNegativesRanking_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_Triplet (loss: Triplet) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_Triplet/finetuned_all-MiniLM-L6-v2_Triplet_evaluation_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each fine-tuned models (i.e. for each model-loss combination)\n",
    "for model_name in model_names:\n",
    "    for loss in losses:\n",
    "        # Build the fine-tuned model path used during training\n",
    "        finetuned_model_path = f\"models/finetuned/{model_name}_{loss}\"\n",
    "        # Create a unique folder name that includes both model name and loss\n",
    "        model_name_clean = f\"{model_name}_{loss}\"\n",
    "        true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "        pred_labels_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "        results_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "        result_name = f\"finetuned_{model_name_clean}\"\n",
    "\n",
    "        print(f\"\\n------Evaluating fine-tuned model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "        %run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "                --team_name { result_name } \\\n",
    "                --true_labels_dir { true_labels_dir } \\\n",
    "                --pred_labels_dir { pred_labels_dir } \\\n",
    "                --results_dir { results_dir }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a313a4b87661b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T19:07:18.777133Z",
     "start_time": "2025-02-19T19:04:34.406821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_coSENT (loss: coSENT) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_coSENT/finetuned_all-MiniLM-L6-v2_coSENT_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_AnglE (loss: AnglE) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_AnglE/finetuned_all-MiniLM-L6-v2_AnglE_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_CosineSimilarity (loss: CosineSimilarity) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_CosineSimilarity/finetuned_all-MiniLM-L6-v2_CosineSimilarity_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_MultipleNegativesRanking (loss: MultipleNegativesRanking) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_MultipleNegativesRanking/finetuned_all-MiniLM-L6-v2_MultipleNegativesRanking_evaluation_metrics.xlsx\n",
      "\n",
      "------Evaluating fine-tuned model: models/finetuned/all-MiniLM-L6-v2_Triplet (loss: Triplet) ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/finetuned_all-MiniLM-L6-v2_Triplet/finetuned_all-MiniLM-L6-v2_Triplet_evaluation_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each fine-tuned models (i.e. for each model-loss combination)\n",
    "for model_name in model_names:\n",
    "    for loss in losses:\n",
    "        # Build the fine-tuned model path used during training\n",
    "        finetuned_model_path = f\"models/finetuned/{model_name}_{loss}\"\n",
    "        # Create a unique folder name that includes both model name and loss\n",
    "        model_name_clean = f\"{model_name}_{loss}\"\n",
    "        true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "        pred_labels_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "        results_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "        result_name = f\"finetuned_{model_name_clean}\"\n",
    "\n",
    "        print(f\"\\n------Evaluating fine-tuned model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "        %run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "                --team_name { result_name } \\\n",
    "                --true_labels_dir { true_labels_dir } \\\n",
    "                --pred_labels_dir { pred_labels_dir } \\\n",
    "                --results_dir { results_dir }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69eebae",
   "metadata": {},
   "source": [
    "## Use MLP instead of cosine similarity for tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb11ecb",
   "metadata": {},
   "source": [
    "#### Train the MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading model...\n",
      "Model loaded.\n",
      "Loading GND tags and building mapping...\n",
      "Loaded 79427 GND tags.\n",
      "Building training examples...\n",
      "Found 41902 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building examples: 100%|██████████| 41902/41902 [16:59<00:00, 41.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 87896 training examples.\n",
      "Building evaluation examples...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building examples: 100%|██████████| 6980/6980 [03:30<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 14711 evaluation examples.\n",
      "Getting embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cc6a19269c439c98776a6a92c8539c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded anchors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ffd08286ab4c498d3737ceac6b1661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded positives\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461b15ff43e04d01a03d5fa42e35e161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded negatives\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9b11fff5e840e4a2f0e1985950b7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded anchors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a842beebd4a4cb5bb3f4070e3d16a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded positives\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab2d7e0d9be4c3486d6d2f30da708ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/460 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded negatives\n",
      "Embeddings obtained.\n",
      "Epoch 1, Iteration 2000, Loss: 0.6792119338214397\n",
      "Epoch 1, Iteration 4000, Loss: 0.6538356104195118\n",
      "Epoch 1, Iteration 6000, Loss: 0.6302781555205583\n",
      "Epoch 1, Iteration 8000, Loss: 0.6118429448734969\n",
      "Epoch 1, Iteration 10000, Loss: 0.5945017095729709\n",
      "\tValidation: Iteration 500, Loss: 0.4766877815127373\n",
      "\tValidation: Iteration 1000, Loss: 0.476679024413228\n",
      "\tValidation: Iteration 1500, Loss: 0.48017379718025527\n",
      "End of epoch 1, Training loss: 0.5871904732041855, Validation Loss: 0.47794387575042446\n",
      "--------------------------------------------------\n",
      "Epoch 2, Iteration 2000, Loss: 0.492627612054348\n",
      "Epoch 2, Iteration 4000, Loss: 0.4840868377313018\n",
      "Epoch 2, Iteration 6000, Loss: 0.4740854501153032\n",
      "Epoch 2, Iteration 8000, Loss: 0.46222490896470847\n",
      "Epoch 2, Iteration 10000, Loss: 0.4498818259485066\n",
      "\tValidation: Iteration 500, Loss: 0.28805169320851565\n",
      "\tValidation: Iteration 1000, Loss: 0.2891920098699629\n",
      "\tValidation: Iteration 1500, Loss: 0.3367441195721428\n",
      "End of epoch 2, Training loss: 0.444272984528228, Validation Loss: 0.3491981118945825\n",
      "--------------------------------------------------\n",
      "Epoch 3, Iteration 2000, Loss: 0.3730476471967995\n",
      "Epoch 3, Iteration 4000, Loss: 0.36393617451004684\n",
      "Epoch 3, Iteration 6000, Loss: 0.3558061127637823\n",
      "Epoch 3, Iteration 8000, Loss: 0.3493812251249328\n",
      "Epoch 3, Iteration 10000, Loss: 0.3437589296765626\n",
      "\tValidation: Iteration 500, Loss: 0.2564914083555341\n",
      "\tValidation: Iteration 1000, Loss: 0.2424523228108883\n",
      "\tValidation: Iteration 1500, Loss: 0.27085659484316904\n",
      "End of epoch 3, Training loss: 0.3412812633331907, Validation Loss: 0.2778505014823856\n",
      "--------------------------------------------------\n",
      "Epoch 4, Iteration 2000, Loss: 0.30447976605780425\n",
      "Epoch 4, Iteration 4000, Loss: 0.300119210283272\n",
      "Epoch 4, Iteration 6000, Loss: 0.29830163458983106\n",
      "Epoch 4, Iteration 8000, Loss: 0.29639032094646245\n",
      "Epoch 4, Iteration 10000, Loss: 0.29423216958977283\n",
      "\tValidation: Iteration 500, Loss: 0.23795641371980308\n",
      "\tValidation: Iteration 1000, Loss: 0.2242481624763459\n",
      "\tValidation: Iteration 1500, Loss: 0.24479781327272454\n",
      "End of epoch 4, Training loss: 0.2932876116586245, Validation Loss: 0.24623612122728716\n",
      "--------------------------------------------------\n",
      "Epoch 5, Iteration 2000, Loss: 0.2737183630708605\n",
      "Epoch 5, Iteration 4000, Loss: 0.2708503333646804\n",
      "Epoch 5, Iteration 6000, Loss: 0.26905891234489776\n",
      "Epoch 5, Iteration 8000, Loss: 0.26846973329782486\n",
      "Epoch 5, Iteration 10000, Loss: 0.2680808193642646\n",
      "\tValidation: Iteration 500, Loss: 0.2216948100104928\n",
      "\tValidation: Iteration 1000, Loss: 0.2097357261069119\n",
      "\tValidation: Iteration 1500, Loss: 0.2293576388185223\n",
      "End of epoch 5, Training loss: 0.26741184759927455, Validation Loss: 0.2296844252495094\n",
      "--------------------------------------------------\n",
      "Epoch 6, Iteration 2000, Loss: 0.25131501648016275\n",
      "Epoch 6, Iteration 4000, Loss: 0.2530809295475483\n",
      "Epoch 6, Iteration 6000, Loss: 0.24994296861998738\n",
      "Epoch 6, Iteration 8000, Loss: 0.24819543104129843\n",
      "Epoch 6, Iteration 10000, Loss: 0.24742797347325832\n",
      "\tValidation: Iteration 500, Loss: 0.18307101614400745\n",
      "\tValidation: Iteration 1000, Loss: 0.18250678775645793\n",
      "\tValidation: Iteration 1500, Loss: 0.21787324655180176\n",
      "End of epoch 6, Training loss: 0.24720564158027275, Validation Loss: 0.2203658131437904\n",
      "--------------------------------------------------\n",
      "Epoch 7, Iteration 2000, Loss: 0.23456090275943278\n",
      "Epoch 7, Iteration 4000, Loss: 0.23770697168819607\n",
      "Epoch 7, Iteration 6000, Loss: 0.23656340211381516\n",
      "Epoch 7, Iteration 8000, Loss: 0.23381649885326625\n",
      "Epoch 7, Iteration 10000, Loss: 0.2332741273868829\n",
      "\tValidation: Iteration 500, Loss: 0.20767475092411042\n",
      "\tValidation: Iteration 1000, Loss: 0.19051092438213527\n",
      "\tValidation: Iteration 1500, Loss: 0.207008984417965\n",
      "End of epoch 7, Training loss: 0.23306887144653635, Validation Loss: 0.20812978284851794\n",
      "--------------------------------------------------\n",
      "Epoch 8, Iteration 2000, Loss: 0.21676809464674443\n",
      "Epoch 8, Iteration 4000, Loss: 0.22172867502691224\n",
      "Epoch 8, Iteration 6000, Loss: 0.22142519970672825\n",
      "Epoch 8, Iteration 8000, Loss: 0.2216144628834445\n",
      "Epoch 8, Iteration 10000, Loss: 0.22035698645245283\n",
      "\tValidation: Iteration 500, Loss: 0.1996344775520265\n",
      "\tValidation: Iteration 1000, Loss: 0.18593732512183486\n",
      "\tValidation: Iteration 1500, Loss: 0.20105396468564868\n",
      "End of epoch 8, Training loss: 0.220016715580892, Validation Loss: 0.19967344966111883\n",
      "--------------------------------------------------\n",
      "Epoch 9, Iteration 2000, Loss: 0.2124976958082989\n",
      "Epoch 9, Iteration 4000, Loss: 0.21031221016868948\n",
      "Epoch 9, Iteration 6000, Loss: 0.21136910900007932\n",
      "Epoch 9, Iteration 8000, Loss: 0.20968277254444548\n",
      "Epoch 9, Iteration 10000, Loss: 0.20870276262853293\n",
      "\tValidation: Iteration 500, Loss: 0.17985768720880152\n",
      "\tValidation: Iteration 1000, Loss: 0.17053091471642257\n",
      "\tValidation: Iteration 1500, Loss: 0.19274874615917603\n",
      "End of epoch 9, Training loss: 0.2086625300909633, Validation Loss: 0.19420999901742958\n",
      "--------------------------------------------------\n",
      "Epoch 10, Iteration 2000, Loss: 0.20351928844396025\n",
      "Epoch 10, Iteration 4000, Loss: 0.19931385607691482\n",
      "Epoch 10, Iteration 6000, Loss: 0.19926704216655344\n",
      "Epoch 10, Iteration 8000, Loss: 0.19890071361069567\n",
      "Epoch 10, Iteration 10000, Loss: 0.1993626041373238\n",
      "\tValidation: Iteration 500, Loss: 0.2448796244263649\n",
      "\tValidation: Iteration 1000, Loss: 0.21481894847098737\n",
      "\tValidation: Iteration 1500, Loss: 0.2008012637005498\n",
      "End of epoch 10, Training loss: 0.19911302493711727, Validation Loss: 0.191431608855777\n",
      "--------------------------------------------------\n",
      "Epoch 11, Iteration 2000, Loss: 0.18927217497862875\n",
      "Epoch 11, Iteration 4000, Loss: 0.18789211323275232\n",
      "Epoch 11, Iteration 6000, Loss: 0.18884832043154165\n",
      "Epoch 11, Iteration 8000, Loss: 0.1891047969692154\n",
      "Epoch 11, Iteration 10000, Loss: 0.18968000566568224\n",
      "\tValidation: Iteration 500, Loss: 0.1946603857446462\n",
      "\tValidation: Iteration 1000, Loss: 0.17513747192546725\n",
      "\tValidation: Iteration 1500, Loss: 0.1851856947168708\n",
      "End of epoch 11, Training loss: 0.1898940648840181, Validation Loss: 0.18445245236109753\n",
      "--------------------------------------------------\n",
      "Epoch 12, Iteration 2000, Loss: 0.180779034670908\n",
      "Epoch 12, Iteration 4000, Loss: 0.1805675892555155\n",
      "Epoch 12, Iteration 6000, Loss: 0.18156674351372445\n",
      "Epoch 12, Iteration 8000, Loss: 0.18180547376174946\n",
      "Epoch 12, Iteration 10000, Loss: 0.1812211006604135\n",
      "\tValidation: Iteration 500, Loss: 0.15804194493126125\n",
      "\tValidation: Iteration 1000, Loss: 0.1516686636158265\n",
      "\tValidation: Iteration 1500, Loss: 0.17904028023189555\n",
      "End of epoch 12, Training loss: 0.1814489205071776, Validation Loss: 0.18245520666489795\n",
      "--------------------------------------------------\n",
      "Epoch 13, Iteration 2000, Loss: 0.17530379921710118\n",
      "Epoch 13, Iteration 4000, Loss: 0.17527757893013768\n",
      "Epoch 13, Iteration 6000, Loss: 0.17504489536257462\n",
      "Epoch 13, Iteration 8000, Loss: 0.17588009551516734\n",
      "Epoch 13, Iteration 10000, Loss: 0.17533101819278674\n",
      "\tValidation: Iteration 500, Loss: 0.2124734227899462\n",
      "\tValidation: Iteration 1000, Loss: 0.1878147853789851\n",
      "\tValidation: Iteration 1500, Loss: 0.18276690203882753\n",
      "End of epoch 13, Training loss: 0.1755024595425154, Validation Loss: 0.1763459555212208\n",
      "--------------------------------------------------\n",
      "Epoch 14, Iteration 2000, Loss: 0.16248522034706547\n",
      "Epoch 14, Iteration 4000, Loss: 0.1665435197468614\n",
      "Epoch 14, Iteration 6000, Loss: 0.16756061722858187\n",
      "Epoch 14, Iteration 8000, Loss: 0.16864911037049024\n",
      "Epoch 14, Iteration 10000, Loss: 0.16893621649979615\n",
      "\tValidation: Iteration 500, Loss: 0.160027188337408\n",
      "\tValidation: Iteration 1000, Loss: 0.1520313202268444\n",
      "\tValidation: Iteration 1500, Loss: 0.17406044374747823\n",
      "End of epoch 14, Training loss: 0.16896859687217555, Validation Loss: 0.1742160524400645\n",
      "--------------------------------------------------\n",
      "Epoch 15, Iteration 2000, Loss: 0.15850806580483914\n",
      "Epoch 15, Iteration 4000, Loss: 0.1577454371250933\n",
      "Epoch 15, Iteration 6000, Loss: 0.15817958408275928\n",
      "Epoch 15, Iteration 8000, Loss: 0.15963343366835034\n",
      "Epoch 15, Iteration 10000, Loss: 0.1600234732521232\n",
      "\tValidation: Iteration 500, Loss: 0.19142966773267836\n",
      "\tValidation: Iteration 1000, Loss: 0.16736467471206562\n",
      "\tValidation: Iteration 1500, Loss: 0.17302402567025274\n",
      "End of epoch 15, Training loss: 0.1600433639431247, Validation Loss: 0.17210119343557723\n",
      "--------------------------------------------------\n",
      "Epoch 16, Iteration 2000, Loss: 0.15295914197992533\n",
      "Epoch 16, Iteration 4000, Loss: 0.15435882909293286\n",
      "Epoch 16, Iteration 6000, Loss: 0.15505962018839395\n",
      "Epoch 16, Iteration 8000, Loss: 0.15508696516382042\n",
      "Epoch 16, Iteration 10000, Loss: 0.1551025669899769\n",
      "\tValidation: Iteration 500, Loss: 0.16148587885592133\n",
      "\tValidation: Iteration 1000, Loss: 0.14724753873376176\n",
      "\tValidation: Iteration 1500, Loss: 0.16769747781970848\n",
      "End of epoch 16, Training loss: 0.15540898849934548, Validation Loss: 0.1704660934140848\n",
      "--------------------------------------------------\n",
      "Epoch 17, Iteration 2000, Loss: 0.1469101379318163\n",
      "Epoch 17, Iteration 4000, Loss: 0.14763296146586072\n",
      "Epoch 17, Iteration 6000, Loss: 0.14863570354304587\n",
      "Epoch 17, Iteration 8000, Loss: 0.14993054490489885\n",
      "Epoch 17, Iteration 10000, Loss: 0.15038704711790196\n",
      "\tValidation: Iteration 500, Loss: 0.15800036250334232\n",
      "\tValidation: Iteration 1000, Loss: 0.14246795751154423\n",
      "\tValidation: Iteration 1500, Loss: 0.16479018717755875\n",
      "End of epoch 17, Training loss: 0.1507587008378027, Validation Loss: 0.16842342870408197\n",
      "--------------------------------------------------\n",
      "Epoch 18, Iteration 2000, Loss: 0.1430289815508295\n",
      "Epoch 18, Iteration 4000, Loss: 0.14296181575092487\n",
      "Epoch 18, Iteration 6000, Loss: 0.1438424538737163\n",
      "Epoch 18, Iteration 8000, Loss: 0.14407669223716948\n",
      "Epoch 18, Iteration 10000, Loss: 0.14383226617276668\n",
      "\tValidation: Iteration 500, Loss: 0.19734552871529012\n",
      "\tValidation: Iteration 1000, Loss: 0.1709596508811228\n",
      "\tValidation: Iteration 1500, Loss: 0.16972742702284208\n",
      "End of epoch 18, Training loss: 0.14384965497669458, Validation Loss: 0.16584684872744548\n",
      "--------------------------------------------------\n",
      "Epoch 19, Iteration 2000, Loss: 0.13985397171624936\n",
      "Epoch 19, Iteration 4000, Loss: 0.13984094932710286\n",
      "Epoch 19, Iteration 6000, Loss: 0.1390356935086505\n",
      "Epoch 19, Iteration 8000, Loss: 0.13964371897507227\n",
      "Epoch 19, Iteration 10000, Loss: 0.1393378795832861\n",
      "\tValidation: Iteration 500, Loss: 0.15382590602058918\n",
      "\tValidation: Iteration 1000, Loss: 0.1438359838281758\n",
      "\tValidation: Iteration 1500, Loss: 0.162971589930666\n",
      "End of epoch 19, Training loss: 0.13919509367317065, Validation Loss: 0.1642312523306263\n",
      "--------------------------------------------------\n",
      "Epoch 20, Iteration 2000, Loss: 0.12988529451959765\n",
      "Epoch 20, Iteration 4000, Loss: 0.13014969991182443\n",
      "Epoch 20, Iteration 6000, Loss: 0.13162947803145894\n",
      "Epoch 20, Iteration 8000, Loss: 0.13284656712325524\n",
      "Epoch 20, Iteration 10000, Loss: 0.13278300951891578\n",
      "\tValidation: Iteration 500, Loss: 0.193607000390999\n",
      "\tValidation: Iteration 1000, Loss: 0.17584108331939205\n",
      "\tValidation: Iteration 1500, Loss: 0.1701681330561017\n",
      "End of epoch 20, Training loss: 0.13296829269252275, Validation Loss: 0.1627958809955389\n",
      "--------------------------------------------------\n",
      "Epoch 21, Iteration 2000, Loss: 0.12755013328348286\n",
      "Epoch 21, Iteration 4000, Loss: 0.12762438944657334\n",
      "Epoch 21, Iteration 6000, Loss: 0.12918331445699247\n",
      "Epoch 21, Iteration 8000, Loss: 0.1287397814608994\n",
      "Epoch 21, Iteration 10000, Loss: 0.12866448548544432\n",
      "\tValidation: Iteration 500, Loss: 0.17218675701413302\n",
      "\tValidation: Iteration 1000, Loss: 0.1521350240437314\n",
      "\tValidation: Iteration 1500, Loss: 0.16118736891634763\n",
      "End of epoch 21, Training loss: 0.1289220369662041, Validation Loss: 0.16087179887399702\n",
      "--------------------------------------------------\n",
      "Epoch 22, Iteration 2000, Loss: 0.12148765887296759\n",
      "Epoch 22, Iteration 4000, Loss: 0.12235802686680108\n",
      "Epoch 22, Iteration 6000, Loss: 0.12208727024837086\n",
      "Epoch 22, Iteration 8000, Loss: 0.12309733686837716\n",
      "Epoch 22, Iteration 10000, Loss: 0.12398399037874769\n",
      "\tValidation: Iteration 500, Loss: 0.11463899047975429\n",
      "\tValidation: Iteration 1000, Loss: 0.1114468794966815\n",
      "\tValidation: Iteration 1500, Loss: 0.15914795367784487\n",
      "End of epoch 22, Training loss: 0.12385186631123746, Validation Loss: 0.1715916842758395\n",
      "--------------------------------------------------\n",
      "Epoch 23, Iteration 2000, Loss: 0.1183688841627445\n",
      "Epoch 23, Iteration 4000, Loss: 0.11738086295267568\n",
      "Epoch 23, Iteration 6000, Loss: 0.118631069043496\n",
      "Epoch 23, Iteration 8000, Loss: 0.11973980071925325\n",
      "Epoch 23, Iteration 10000, Loss: 0.11991910080974921\n",
      "\tValidation: Iteration 500, Loss: 0.1638108942778781\n",
      "\tValidation: Iteration 1000, Loss: 0.1512712328028865\n",
      "\tValidation: Iteration 1500, Loss: 0.161814632468236\n",
      "End of epoch 23, Training loss: 0.12017374331258047, Validation Loss: 0.1594519495294045\n",
      "--------------------------------------------------\n",
      "Epoch 24, Iteration 2000, Loss: 0.11252620765566826\n",
      "Epoch 24, Iteration 4000, Loss: 0.11431027320364956\n",
      "Epoch 24, Iteration 6000, Loss: 0.11464352716043746\n",
      "Epoch 24, Iteration 8000, Loss: 0.11566785787671688\n",
      "Epoch 24, Iteration 10000, Loss: 0.11592004246702418\n",
      "\tValidation: Iteration 500, Loss: 0.18878006402822212\n",
      "\tValidation: Iteration 1000, Loss: 0.16745924627617934\n",
      "\tValidation: Iteration 1500, Loss: 0.1665194337431652\n",
      "End of epoch 24, Training loss: 0.11608126603470915, Validation Loss: 0.15968487128048686\n",
      "--------------------------------------------------\n",
      "Epoch 25, Iteration 2000, Loss: 0.11089088670822093\n",
      "Epoch 25, Iteration 4000, Loss: 0.11060503237546072\n",
      "Epoch 25, Iteration 6000, Loss: 0.1111802186385612\n",
      "Epoch 25, Iteration 8000, Loss: 0.11101428529257829\n",
      "Epoch 25, Iteration 10000, Loss: 0.11165233565605012\n",
      "\tValidation: Iteration 500, Loss: 0.1771730317212641\n",
      "\tValidation: Iteration 1000, Loss: 0.16318000633083285\n",
      "\tValidation: Iteration 1500, Loss: 0.1637930937471489\n",
      "End of epoch 25, Training loss: 0.11208803472875635, Validation Loss: 0.1571515788308478\n",
      "--------------------------------------------------\n",
      "Epoch 26, Iteration 2000, Loss: 0.10567624191113283\n",
      "Epoch 26, Iteration 4000, Loss: 0.10670295520784566\n",
      "Epoch 26, Iteration 6000, Loss: 0.1074670595814047\n",
      "Epoch 26, Iteration 8000, Loss: 0.1083102032077295\n",
      "Epoch 26, Iteration 10000, Loss: 0.10865013720182469\n",
      "\tValidation: Iteration 500, Loss: 0.17217203540960327\n",
      "\tValidation: Iteration 1000, Loss: 0.1572379319325555\n",
      "\tValidation: Iteration 1500, Loss: 0.16537518704139317\n",
      "End of epoch 26, Training loss: 0.10888041985719672, Validation Loss: 0.1615230749687104\n",
      "--------------------------------------------------\n",
      "Epoch 27, Iteration 2000, Loss: 0.10003405634243973\n",
      "Epoch 27, Iteration 4000, Loss: 0.10204324512393213\n",
      "Epoch 27, Iteration 6000, Loss: 0.10284069860128996\n",
      "Epoch 27, Iteration 8000, Loss: 0.10438152585027274\n",
      "Epoch 27, Iteration 10000, Loss: 0.10494003537083045\n",
      "\tValidation: Iteration 500, Loss: 0.14807664069905876\n",
      "\tValidation: Iteration 1000, Loss: 0.14079751267889515\n",
      "\tValidation: Iteration 1500, Loss: 0.15845992803480477\n",
      "End of epoch 27, Training loss: 0.10523769779601606, Validation Loss: 0.15759601098342985\n",
      "--------------------------------------------------\n",
      "Epoch 28, Iteration 2000, Loss: 0.09734348707576282\n",
      "Epoch 28, Iteration 4000, Loss: 0.09894575690830243\n",
      "Epoch 28, Iteration 6000, Loss: 0.10091597223819311\n",
      "Epoch 28, Iteration 8000, Loss: 0.10195561052461562\n",
      "Epoch 28, Iteration 10000, Loss: 0.1022824901406304\n",
      "\tValidation: Iteration 500, Loss: 0.198997146573849\n",
      "\tValidation: Iteration 1000, Loss: 0.17594099394557997\n",
      "\tValidation: Iteration 1500, Loss: 0.16704587699690213\n",
      "End of epoch 28, Training loss: 0.10217598429634156, Validation Loss: 0.15870621485803774\n",
      "--------------------------------------------------\n",
      "Epoch 29, Iteration 2000, Loss: 0.09670806016586721\n",
      "Epoch 29, Iteration 4000, Loss: 0.09626815387562965\n",
      "Epoch 29, Iteration 6000, Loss: 0.09670139408815885\n",
      "Epoch 29, Iteration 8000, Loss: 0.09809342438234307\n",
      "Epoch 29, Iteration 10000, Loss: 0.09856412228782428\n",
      "\tValidation: Iteration 500, Loss: 0.15868095986172556\n",
      "\tValidation: Iteration 1000, Loss: 0.14316795674921012\n",
      "\tValidation: Iteration 1500, Loss: 0.15732381403337542\n",
      "End of epoch 29, Training loss: 0.09853496798209256, Validation Loss: 0.15856195200812487\n",
      "--------------------------------------------------\n",
      "Epoch 30, Iteration 2000, Loss: 0.09180564317596145\n",
      "Epoch 30, Iteration 4000, Loss: 0.09301097784907324\n",
      "Epoch 30, Iteration 6000, Loss: 0.09317352352194333\n",
      "Epoch 30, Iteration 8000, Loss: 0.09406457068229793\n",
      "Epoch 30, Iteration 10000, Loss: 0.09450665935938014\n",
      "\tValidation: Iteration 500, Loss: 0.17094241258013063\n",
      "\tValidation: Iteration 1000, Loss: 0.15125749644765166\n",
      "\tValidation: Iteration 1500, Loss: 0.1587433446654274\n",
      "End of epoch 30, Training loss: 0.0950617054370423, Validation Loss: 0.15763283713449547\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "model_name_clean = model_name.split(\"/\")[-1]\n",
    "model_path = f\"{model_name_clean}\"\n",
    "training_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/train\"\n",
    "eval_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "gnd_tags_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"\n",
    "\n",
    "%run binary_mlp.py \\\n",
    "        --training_path {training_data_dir} \\\n",
    "        --eval_path {eval_data_dir} \\\n",
    "        --gnd_tags_file {gnd_tags_file} \\\n",
    "        --model_name {model_path} \\\n",
    "        --batch_size 16 \\\n",
    "        --num_epochs 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b2eb4",
   "metadata": {},
   "source": [
    "#### Tag using the embedding models + MLP to measure similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Running tagging with model: all-MiniLM-L6-v2 ------\n",
      "Loading model...\n",
      "Loading GND tags...\n",
      "Encoding tag descriptions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cd36e10b6b4858b8e47299edf4c2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test documents and computing similarities...\n",
      "Found 6980 documents in shared-task-datasets/TIBKAT/tib-core-subjects/data/dev/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading documents: 100%|██████████| 6980/6980 [00:03<00:00, 1847.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935603560ae44146991b4818668788a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/embedding_similarity_tagging.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(mlp_model, map_location=DEVICE)\n",
      "Tagging documents: 100%|██████████| 6980/6980 [12:56<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Individual results saved in corresponding files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name_folder = model_name.split(\"/\")[-1]\n",
    "tag_embeddings_file = f\"results/mlp_{model_name_folder}/tag_embeddings.json\"  # Where to save the tag embeddings\n",
    "doc_embeddings_file = f\"embeddings/mlp_{model_name_folder}/doc_embeddings.pt\"  # Where to save the document embeddings\n",
    "results_dir = f\"results/mlp_{model_name_folder}\"  # Where to save the tagging results\n",
    "docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev/\"  # Documents to tag\n",
    "tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "mlp_model = f\"models/mlp/{model_name_folder}.pth\"\n",
    "\n",
    "print(f\"\\n------Running tagging with model: {model_name} ------\")\n",
    "%run embedding_similarity_tagging.py \\\n",
    "        --model_name { model_name } \\\n",
    "        --tags_file { tag_file } \\\n",
    "        --tag_embeddings_file { tag_embeddings_file } \\\n",
    "        --doc_embeddings_file { doc_embeddings_file } \\\n",
    "        --results_dir { results_dir } \\\n",
    "        --docs_path { docs_path } \\\n",
    "        --mlp_model { mlp_model }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effafe5",
   "metadata": {},
   "source": [
    "#### Evaluate embedding+MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e6310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Evaluating fine-tuned model: all-MiniLM-L6-v2 ------\n",
      "\n",
      "LLMs4Subjects Shared Task -- Evaluations\n",
      "\n",
      "Reading the True GND labels...\n",
      "Reading the Predicted GND labels...\n",
      "Exception Occured: 'utf-8' codec can't decode byte 0x91 in position 10: invalid start byte\n",
      "\n",
      "Evaluating the directory structure of the predicted folder...\n",
      "\n",
      "Evaluating the predicted GND labels...\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 5\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 5\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 10\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 10\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 15\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 15\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 20\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 20\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 25\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 25\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 30\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 30\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 35\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 35\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 40\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 40\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 45\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 45\n",
      "\n",
      "Evaluating GND Subject Codes -- Granularity Level: Combined Language and Record-levels and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Record Type level and k: 50\n",
      "Evaluating GND Subject Codes -- Granularity Level: Language level and k: 50\n",
      "\n",
      "File containing the evaluation metrics score is saved at location: results/mlp_all-MiniLM-L6-v2/mlp_all-MiniLM-L6-v2_evaluation_metrics.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tagging results of embedding+MLP models using the evaluation script\n",
    "\n",
    "# Build the fine-tuned model path used during training\n",
    "# Create a unique folder name that includes both model name and loss\n",
    "true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "pred_labels_dir = f\"results/mlp_{model_name_folder}\"\n",
    "results_dir = f\"results/mlp_{model_name_folder}\"\n",
    "result_name = f\"mlp_{model_name_folder}\"\n",
    "\n",
    "print(f\"\\n------Evaluating fine-tuned model: {model_name_folder} ------\")\n",
    "%run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "        --team_name { result_name } \\\n",
    "        --true_labels_dir { true_labels_dir } \\\n",
    "        --pred_labels_dir { pred_labels_dir } \\\n",
    "        --results_dir { results_dir }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11ac23",
   "metadata": {},
   "source": [
    "# Combine best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c4ba43",
   "metadata": {},
   "source": [
    "### Longer finetuning using best Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "loss = \"MultipleNegativesRanking\"\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee22346",
   "metadata": {},
   "source": [
    "#### Execute fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n------Fine-tuning model: {model_name} ------\")\n",
    "model_name_clean = model_name.split(\"/\")[-1]\n",
    "\n",
    "# Common directories and files\n",
    "training_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/train\"\n",
    "eval_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "gnd_tags_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"\n",
    "\n",
    "# Modify the output path to include the loss function name\n",
    "output_model_path = f\"models/finetuned/{model_name_clean}_{loss}_{epochs}epochs\"\n",
    "print(f\"Using loss: {loss}, saving to: {output_model_path}\")\n",
    "\n",
    "# Run the fine-tuning script with the specified loss\n",
    "%run finetune_sentence_transformer.py \\\n",
    "        --training_path { training_data_dir } \\\n",
    "        --eval_path { eval_data_dir } \\\n",
    "        --gnd_tags_file { gnd_tags_file } \\\n",
    "        --model_name { model_name } \\\n",
    "        --output_model_path { output_model_path } \\\n",
    "        --batch_size 16 \\\n",
    "        --num_epochs {epochs} \\\n",
    "        --loss { loss }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c022d16",
   "metadata": {},
   "source": [
    "#### Tag using the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct the path where the finetuned model is saved\n",
    "finetuned_model_path = f\"models/finetuned/{model_name}_{loss}_{epochs}epochs\"\n",
    "# Use a folder name that includes both the model and loss to save the tagging results\n",
    "model_name_folder = f\"{model_name}_{loss}\"\n",
    "tag_embeddings_file = f\"results/finetuned_{model_name_folder}/tag_embeddings.json\"  # Where to save the tag embeddings\n",
    "results_dir = f\"results/finetuned_{model_name_folder}\"  # Where to save the tagging results\n",
    "docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"  # Documents to tag\n",
    "tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "\n",
    "print(f\"\\n------Running tagging with model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "%run embedding_similarity_tagging.py \\\n",
    "        --model_name { finetuned_model_path } \\\n",
    "        --tags_file { tag_file } \\\n",
    "        --tag_embeddings_file { tag_embeddings_file } \\\n",
    "        --results_dir { results_dir } \\\n",
    "        --docs_path { docs_path }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4486b6a6",
   "metadata": {},
   "source": [
    "#### Evaluate the fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de083d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the fine-tuned model path used during training\n",
    "finetuned_model_path = f\"models/finetuned/{model_name}_{loss}_{epochs}epochs\"\n",
    "# Create a unique folder name that includes both model name and loss\n",
    "model_name_clean = f\"{model_name}_{loss}\"\n",
    "true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "pred_labels_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "results_dir = f\"results/finetuned_{model_name_clean}\"\n",
    "result_name = f\"finetuned_{model_name_clean}\"\n",
    "\n",
    "print(f\"\\n------Evaluating fine-tuned model: {finetuned_model_path} (loss: {loss}) ------\")\n",
    "%run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "        --team_name { result_name } \\\n",
    "        --true_labels_dir { true_labels_dir } \\\n",
    "        --pred_labels_dir { pred_labels_dir } \\\n",
    "        --results_dir { results_dir }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57f3260",
   "metadata": {},
   "source": [
    "### Train MLP on top of finetuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd0230",
   "metadata": {},
   "source": [
    "#### Train the MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67433278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"models/finetuned/{model_name}_{loss}_{epochs}epochs\"\n",
    "\n",
    "training_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/train\"\n",
    "eval_data_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "gnd_tags_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"\n",
    "\n",
    "%run binary_mlp.py \\\n",
    "        --training_path {training_data_dir} \\\n",
    "        --eval_path {eval_data_dir} \\\n",
    "        --gnd_tags_file {gnd_tags_file} \\\n",
    "        --model_name {model_path} \\\n",
    "        --batch_size 16 \\\n",
    "        --num_epochs 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca41da",
   "metadata": {},
   "source": [
    "#### Tag using the embedding models + MLP to measure similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc733c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_folder = model_name.split(\"/\")[-1]\n",
    "tag_embeddings_file = f\"results/mlp_{model_name_folder}/tag_embeddings_finetuned.json\"  # Where to save the tag embeddings\n",
    "doc_embeddings_file = f\"embeddings/mlp_{model_name_folder}/doc_embeddings_finetuned.pt\"  # Where to save the document embeddings\n",
    "results_dir = f\"results/mlp_{model_name_folder}/finetuned\"  # Where to save the tagging results\n",
    "docs_path = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev/\"  # Documents to tag\n",
    "tag_file = \"shared-task-datasets/GND/dataset/GND-Subjects-tib-core.json\"  # Tag list definition\n",
    "mlp_model = f\"models/mlp/{model_name_folder}.pth\"\n",
    "\n",
    "print(f\"\\n------Running tagging with model: {model_name} ------\")\n",
    "%run embedding_similarity_tagging.py \\\n",
    "        --model_name { model_name } \\\n",
    "        --tags_file { tag_file } \\\n",
    "        --tag_embeddings_file { tag_embeddings_file } \\\n",
    "        --doc_embeddings_file { doc_embeddings_file } \\\n",
    "        --results_dir { results_dir } \\\n",
    "        --docs_path { docs_path } \\\n",
    "        --mlp_model { mlp_model }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21326139",
   "metadata": {},
   "source": [
    "#### Evaluate embedding+MLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7447cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tagging results of embedding+MLP models using the evaluation script\n",
    "\n",
    "# Build the fine-tuned model path used during training\n",
    "# Create a unique folder name that includes both model name and loss\n",
    "true_labels_dir = \"shared-task-datasets/TIBKAT/tib-core-subjects/data/dev\"\n",
    "pred_labels_dir = f\"results/mlp_{model_name_folder}\"\n",
    "results_dir = f\"results/mlp_{model_name_folder}/finetuned\"\n",
    "result_name = f\"mlp_{model_name_folder}_finetuned\"\n",
    "\n",
    "print(f\"\\n------Evaluating fine-tuned model: {model_name_folder} ------\")\n",
    "%run \"shared-task-eval-script/llms4subjects-evaluation.py\" \\\n",
    "        --team_name { result_name } \\\n",
    "        --true_labels_dir { true_labels_dir } \\\n",
    "        --pred_labels_dir { pred_labels_dir } \\\n",
    "        --results_dir { results_dir }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
